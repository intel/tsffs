// Copyright (C) 2023 Intel Corporation
// SPDX-License-Identifier: Apache-2.0

use std::ffi::CStr;

use anyhow::{anyhow, bail, Result};
use raw_cstr::AsRawCstr;
use simics::api::{
    get_interface, read_phys_memory, write_phys_memory, Access, ConfObject, GenericAddress,
    IntRegisterInterface, ProcessorInfoV2Interface,
};

use crate::driver::{StartBuffer, StartSize};

use super::ArchitectureOperations;

/// The default register the fuzzer expects to contain a pointer to an area to write
/// each testcase into when using an in-target harness
pub const DEFAULT_TESTCASE_AREA_REGISTER_NAME: &str = "rdi";
/// The default register the fuzzer expects to contain a pointer to a variable,
/// initially containing the maximum size of the area pointed to by
/// `DEFAULT_TESTCASE_AREA_REGISTER_NAME`, which will be written each fuzzer execution
/// to contain the actual size of the current testcase.
pub const DEFAULT_TESTCASE_SIZE_REGISTER_NAME: &str = "rsi";

pub mod exceptions {
    /// Division errors generated by DIV and IDIV instructions
    pub const DIVIDE_ERROR: i64 = 0;
    pub const DEBUG: i64 = 1;
    pub const NMI_INTERRUPT: i64 = 2;
    /// INT3 instructions
    pub const BREAKPOINT: i64 = 3;
    /// INT0 instructions
    pub const OVERFLOW: i64 = 4;
    /// BOUND instruction
    pub const BOUND: i64 = 5;
    /// UD instruction or reserved opcode
    pub const INVALID_OPCODE: i64 = 6;
    /// Floating point or WAIT/FWAIT instruction (no math coprocessor)
    pub const DEVICE_NOT_AVAILABLE: i64 = 7;
    /// Any instruction that can generate an exception, NMI, or INTR can cause a double fault,
    /// i.e. on page miss twice.
    pub const DOUBLE_FAULT: i64 = 8;
    /// Floating point instruction overrun coprocessor segment
    pub const COPROCESSOR_SEGMENT_OVERRUN: i64 = 9;
    /// Invalid task switch or TSS access
    pub const INVALID_TSS: i64 = 10;
    /// Error loading segment registers or accessing system segments
    pub const SEGMENT_NOT_PRESENT: i64 = 11;
    /// Stack operations and SS register loads in segmented operation mode
    pub const STACK_SEGMENT_FAULT: i64 = 12;
    /// Error during memory reference or other protection check
    pub const GENERAL_PROTECTION: i64 = 13;
    /// Page fault
    pub const PAGE_FAULT: i64 = 14;
    // NOTE: 15 reserved
    /// Error in floating point math or WAIT/FWAIT instruction
    pub const FLOATING_POINT_ERROR: i64 = 16;
    /// Error in data alignment
    pub const ALIGNMENT_CHECK: i64 = 17;
    /// Error code and source are model dependent
    pub const MACHINE_CHECK: i64 = 18;
    /// Exception in SIMD floating point math
    pub const SIMD_FLOATING_POINT_EXCEPTION: i64 = 19;
    /// Extended page table/VT exception
    pub const VIRTUALIZATION_EXCEPTION: i64 = 20;
    /// Missing ENDBRANCH instruction at the target of an indirect call or jump. Generated by
    /// RET, IRET, RSTORSSP, and SETSSBSY instruction when CET is enabled.
    pub const CONTROL_PROTECTION_EXCEPTION: i64 = 21;
    // NOTE: 22-31 reserved
    // NOTE: 32-255 are maskable interrupts.

    #[repr(i64)]
    pub enum Exception {
        DivideError = 1,
        Debug,
        NmiInterrupt,
        Breakpoint,
        Overflow,
        Bound,
        InvalidOpcode,
        DeviceNotAvailable,
        DoubleFault,
        CoprocessorSegmentOverrun,
        InvalidTss,
        SegmentNotPresent,
        StackSegmentFault,
        GeneralProtection,
        PageFault,
        Reserved0,
        FloatingPointError,
        AlignmentCheck,
        MachineCheck,
        SimdFloatingPointException,
        VirtualizationException,
        ControlProtectionException,
        Other(i64),
    }

    impl From<Exception> for i64 {
        fn from(value: Exception) -> Self {
            match value {
                Exception::Other(i) => i,
                _ => i64::from(value),
            }
        }
    }
}

pub struct X86_64ArchitectureOperations {
    cpu: *mut ConfObject,
    int_register: IntRegisterInterface,
    processor_info_v2: ProcessorInfoV2Interface,
}

impl ArchitectureOperations for X86_64ArchitectureOperations {
    fn new(cpu: *mut ConfObject) -> Result<Self> {
        let mut processor_info_v2: ProcessorInfoV2Interface = get_interface(cpu)?;

        let arch = unsafe { CStr::from_ptr(processor_info_v2.architecture()?) }
            .to_str()?
            .to_string();

        if arch == "x86-64" {
            // Check if the arch is actually x86-64, some x86-64 processors are actually
            // i386 under the hood
            let mut int_register: IntRegisterInterface = get_interface(cpu)?;
            let regs: Vec<u32> = int_register.all_registers()?.try_into()?;
            let reg_names: Vec<String> = regs
                .iter()
                .map(|r| {
                    int_register
                        .get_name(*r as i32)
                        .map_err(|e| anyhow!("Failed to get register name: {e}"))
                        .and_then(|n| {
                            unsafe { CStr::from_ptr(n) }
                                .to_str()
                                .map(|s| s.to_string())
                                .map_err(|e| anyhow!("Failed to convert string: {e}"))
                        })
                })
                .collect::<Result<Vec<_>>>()?;

            if reg_names.iter().any(|n| {
                [
                    "rax", "rbx", "rcx", "rdx", "rdi", "rsi", "rip", "rsp", "rbp", "r8", "r9",
                    "r10", "r11", "r12", "r14", "r15",
                ]
                .contains(&n.to_ascii_lowercase().as_str())
            }) {
                Ok(Self {
                    cpu,
                    int_register,
                    processor_info_v2,
                })
            } else if reg_names.iter().all(|n| {
                ![
                    "rax", "rbx", "rcx", "rdx", "rdi", "rsi", "rip", "rsp", "rbp", "r8", "r9",
                    "r10", "r11", "r12", "r14", "r15",
                ]
                .contains(&n.to_ascii_lowercase().as_str())
            }) {
                bail!("Architecture reports x86-64 but is not actually x86-64")
            } else {
                unreachable!("Register set must either contain a 64-bit register or no registers may be 64-bit");
            }
        } else {
            bail!("Architecture {arch} is not x86-64");
        }
    }

    fn get_magic_start_buffer(&mut self) -> Result<StartBuffer> {
        let number = self
            .int_register
            .get_number(DEFAULT_TESTCASE_AREA_REGISTER_NAME.as_raw_cstr()?)?;

        let logical_address = self.int_register.read(number)?;

        let physical_address_block = self
            .processor_info_v2
            // NOTE: Do we need to support segmented memory via logical_to_physical?
            .logical_to_physical(logical_address, Access::Sim_Access_Read)?;

        // NOTE: -1 signals no valid mapping, but this is equivalent to u64::MAX
        if physical_address_block.valid == 0 {
            bail!("Invalid linear address found in magic start buffer register {number}: {logical_address:#x}");
        } else {
            Ok(StartBuffer {
                physical_address: physical_address_block.address,
                virt: physical_address_block.address != logical_address,
            })
        }
    }

    fn get_magic_start_size(&mut self) -> Result<StartSize> {
        let number = self
            .int_register
            .get_number(DEFAULT_TESTCASE_SIZE_REGISTER_NAME.as_raw_cstr()?)?;
        let logical_address = self.int_register.read(number)?;
        let physical_address_block = self
            .processor_info_v2
            // NOTE: Do we need to support segmented memory via logical_to_physical?
            .logical_to_physical(logical_address, Access::Sim_Access_Read)?;

        // NOTE: -1 signals no valid mapping, but this is equivalent to u64::MAX
        if physical_address_block.valid == 0 {
            bail!("Invalid linear address found in magic start buffer register {number}: {logical_address:#x}");
        }

        let size_size = self.processor_info_v2.get_logical_address_width()? / u8::BITS as i32;
        let size = read_phys_memory(self.cpu, physical_address_block.address, size_size)?;

        Ok(StartSize {
            physical_address: Some(physical_address_block.address),
            initial_size: size,
            virt: physical_address_block.address != logical_address,
        })
    }

    fn write_start(
        &mut self,
        testcase: &[u8],
        buffer: &StartBuffer,
        size: &StartSize,
    ) -> Result<()> {
        let mut testcase = testcase.to_vec();
        testcase.truncate(size.initial_size as usize);

        testcase.chunks(8).try_for_each(|c| {
            println!("Writing {:#x} <- {:?}", buffer.physical_address, c);
            write_phys_memory(self.cpu, buffer.physical_address, c)
        })?;

        let value = testcase
            .len()
            .to_le_bytes()
            .iter()
            .take(self.processor_info_v2.get_logical_address_width()? as usize)
            .cloned()
            .collect::<Vec<_>>();

        if let Some(ref physical_address) = size.physical_address {
            println!(
                "Writing size {:#x} <- {:?}",
                *physical_address,
                value.as_slice()
            );
            write_phys_memory(self.cpu, *physical_address, value.as_slice())?;
        }

        Ok(())
    }

    fn get_start_size(&mut self, size_address: GenericAddress, virt: bool) -> Result<StartSize> {
        let original_size_address = size_address;
        let size_address = if virt {
            let physical_address_block = self
                .processor_info_v2
                // NOTE: Do we need to support segmented memory via logical_to_physical?
                .logical_to_physical(size_address, Access::Sim_Access_Read)?;

            if physical_address_block.valid == 0 {
                bail!("Invalid linear address given for start buffer : {size_address:#x}");
            }

            physical_address_block.address
        } else {
            size_address
        };
        let size_size = self.processor_info_v2.get_logical_address_width()? / u8::BITS as i32;
        let size = read_phys_memory(self.cpu, size_address, size_size)?;

        Ok(StartSize {
            physical_address: Some(size_address),
            initial_size: size,
            virt: original_size_address != size_address,
        })
    }
}
